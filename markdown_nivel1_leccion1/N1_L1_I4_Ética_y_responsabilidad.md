Usar asistentes de programación con IA de forma ética y responsable implica que sus sugerencias sean confiables, útiles para el propósito principal y no perjudiquen a terceros.
Su adopción conlleva desafíos, limitaciones y riesgos que deben atenderse para garantizar un uso seguro y beneficioso.

Programador frente a una pantalla dividida: de un lado beneficios (luz, orden) y del otro riesgos (alertas, candados).
Limitaciones y desafíos técnicos
Antes de confiar plenamente en un asistente de IA, reconoce sus limitaciones:
Falta de transparencia en sus decisiones.
Dependencia excesiva que puede reducir las habilidades técnicas del programador.
Generación de código inseguro o ineficiente.
Riesgos de privacidad y exposición de datos.
Propagación de sesgos presentes en los datos de entrenamiento.
Restricciones técnicas
Solo pueden analizar un volumen limitado de  código a la vez, lo que dificulta proyectos con miles o millones de líneas. Capacidad de contexto.
Funciones avanzadas sujetas a licencias y configuraciones especiales. Pago de licencias.
Desafíos actuales:
Mejorar infraestructura de hardware, software.
Incrementar calidad y precisión de sugerencias.
Gestionar licencias y material protegido.
Adoptar estándares globales para el uso ético y responsable.
Riesgos y regulaciones
El uso de la IA en el desarrollo de software implica riesgos que requieren medidas preventivas y marcos regulatorios:
| Riesgo | Descripción | Regulación |
| --- | --- | --- |
| Derechos de autor | Uso de datos de entrenamiento con material protegido. | Entrenar con datos propios y respetar licencias. |
| Confidencialidad | Exposición de datos personales o código propio. | Limitar la información proporcionada. |
| Autoría | Dificultad para identificar al creador del contenido. | Asumir la responsabilidad tras revisión y validación. |
| Sesgo | Contenido parcial o discriminatorio. | Cuidar la selección de datos de entrenamiento. |
| Inexactitud | Respuestas incorrectas o incompletas. | Validar con experiencia y documentación oficial. |


Principios para uso ético y responsable
Actúan como una guía para maximizar beneficios y minimizar riesgos:
Objetividad: definir el propósito de uso.
Utilidad: usar los resultados con un fin legítimo y beneficioso.
Verificación: comprobar la veracidad de las sugerencias.
Transparencia: informar si se ha usado IA durante el desarrollo.
No discriminación: evitar sesgos y foemntar la equidad.
Responsabilidad: asumir la revisión y validación del código.
Minimización del daño: prevenir consecuencias negativas.
Ver referencia 1

Implicaciones legales del uso de código generado por IA
Además de las buenas prácticas, es fundamental considerar el marco legal:
Propiedad intelectual: la autoría del código no siempre es clara.
Licencias: riesgo de reproducir código restringido.
Responsabilidad legal: los errores son atribuibles al desarrollador.
Protección de datos: cumplir leyes nacionales e internacionales.
Normas y marcos de referencia:
OWASP LLM: guía de uso seguro para modelos de lenguaje.
NIST AI RMF: marco de gestión de riesgos en IA.
ISO/IEC 23894: norma sobre transparencia, seguridad y ética en IA.

Adoptar buenas prácticas, validar cada sugerencia y cumplir con las regulaciones fortalece la confianza e integridad del trabajo del desarrollador.

Referencias gráficas
Referencia 1

Fuentes:
https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-v2025.pdf
https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf
https://cdn.standards.iteh.ai/samples/77304/cb803ee4e9624430a5db177459158b24/ISO-IEC-23894-2023.pdf
https://www.dentons.com/en/insights/articles/2023/april/4/key-legal-considerations-with-generative-ai
